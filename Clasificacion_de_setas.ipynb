{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonfullxr/Classifying-Mushrooms/blob/main/Clasificacion_de_setas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szZoQ6tYiL12"
      },
      "source": [
        "\n",
        "<header>\n",
        "  <h1 align=\"center\">Proyecto Final - Clasificación de Setas</h1>\n",
        "  <h2 align=\"center\">Aprendizaje Automático</h2>\n",
        "  <h3 align=\"center\">CURSO 2023-2024</h3>\n",
        "</header>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <strong>Trabajo realizado por:</strong><br>\n",
        "  Rafael Carrillo Arroyo.<br>\n",
        "  Leon Elliott Fuller.<br>\n",
        "  Pablo Gervilla Miranda. <br>\n",
        "  Andrés Hurtado Morón.<br>\n",
        "  <strong>Correo:</strong> <a href=\"mailto:leonfuller@correo.ugr.es\">leonfuller@correo.ugr.es</a><br>\n",
        "  <strong>Correo:</strong> <a href=\"mailto:rafacarrillo@correo.ugr.es\">rafacarrillo@correo.ugr.es</a><br>\n",
        "  <strong>Correo:</strong> <a href=\"mailto:andreshurtado@correo.ugr.es\">andreshurtado@correo.ugr.es</a><br>\n",
        "</p>\n",
        "\n",
        "---\n",
        "\n",
        "# Introducción\n",
        "\n",
        "Descripcion: Este conjunto de datos incluye 61.069 ejemplos de setas con sombreros basados en 173 especies (353 setas por especie). Cada seta se identifica como definitivamente\n",
        "comestible, definitivamente venenosa o de comestibilidad desconocida y no recomendada\n",
        "(esta ultima clase se combino con la clase venenosa). Se emplean 20 caracterısticas de\n",
        "naturaleza heterogenea para su clasificacion y presentando datos faltantes.\n",
        "Referencias: https://archive.ics.uci.edu/dataset/848/secondary+mushroom+dataset y Wagner, Dennis, Dominik Heider, and Georges Hattab. “Mushroom data creation, curation,\n",
        "and simulation to support classification tasks.”Scientific reports 11.1 (2021): 8134.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vOrR8nkgcnG"
      },
      "source": [
        "***Librerias necesarias:***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "VDdFu4s5TDB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIQvRgbMkr9k",
        "outputId": "04514113-ab9b-4d75-a1b8-16868774b860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.5.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Actualizamos scikit-learn para tener la última versión.\n",
        "import sklearn\n",
        "if sklearn.__version__ < '1.3':\n",
        "  !pip install scikit-learn --upgrade\n",
        "else:\n",
        "  print('La versión de scikit-learn es: ', sklearn.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc5yX95YmYw2"
      },
      "source": [
        "***Cargamos datos***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p7lKWbVhAH1"
      },
      "source": [
        "**1ºForma**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UU67eDRaXpc",
        "outputId": "dec7bdee-091f-49cf-916c-d6115c3f2bd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n",
            "{'uci_id': 848, 'name': 'Secondary Mushroom', 'repository_url': 'https://archive.ics.uci.edu/dataset/848/secondary+mushroom+dataset', 'data_url': 'https://archive.ics.uci.edu/static/public/848/data.csv', 'abstract': 'Dataset of simulated mushrooms for binary classification into edible and poisonous.', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 61068, 'num_features': 20, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 2021, 'last_updated': 'Wed Apr 10 2024', 'dataset_doi': '10.24432/C5FP5Q', 'creators': ['Dennis Wagner', 'D. Heider', 'Georges Hattab'], 'intro_paper': {'title': 'Mushroom data creation, curation, and simulation to support classification tasks', 'authors': 'Dennis Wagner, D. Heider, Georges Hattab', 'published_in': 'Scientific Reports', 'year': 2021, 'url': 'https://www.semanticscholar.org/paper/336be248b6f1c5d77c3c93e89f2e19e7344b0250', 'doi': None}, 'additional_info': {'summary': 'The given information is about the Secondary Mushroom Dataset, the Primary Mushroom Dataset used for the simulation and the respective metadata can be found in the zip.\\n\\nThis dataset includes 61069 hypothetical mushrooms with caps based on 173 species (353 mushrooms\\nper species). Each mushroom is identified as definitely edible, definitely poisonous, or of\\nunknown edibility and not recommended (the latter class was combined with the poisonous class).\\n\\nThe related Python project contains a Python module secondary_data_generation.py\\nused to generate this data based on primary_data_edited.csv also found in the repository.\\nBoth nominal and metrical variables are a result of randomization.\\nThe simulated and ordered by species version is found in secondary_data_generated.csv.\\nThe randomly shuffled version is found in secondary_data_shuffled.csv.', 'purpose': 'Inspired by the Mushroom Data Set of J. Schlimmer: url:https://archive.ics.uci.edu/ml/datasets/Mushroom.', 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'One binary class divided in edible=e and poisonous=p (with the latter one also containing mushrooms of unknown edibility).\\nTwenty remaining variables (n: nominal, m: metrical)\\n1. cap-diameter (m): float number in cm\\n2. cap-shape (n): bell=b, conical=c, convex=x, flat=f,\\nsunken=s, spherical=p, others=o\\n3. cap-surface (n): fibrous=i, grooves=g, scaly=y, smooth=s,\\nshiny=h, leathery=l, silky=k, sticky=t,\\nwrinkled=w, fleshy=e\\n4. cap-color (n): brown=n, buff=b, gray=g, green=r, pink=p,\\npurple=u, red=e, white=w, yellow=y, blue=l,\\norange=o, black=k\\n5. does-bruise-bleed (n): bruises-or-bleeding=t,no=f\\n6. gill-attachment (n): adnate=a, adnexed=x, decurrent=d, free=e,\\nsinuate=s, pores=p, none=f, unknown=?\\n7. gill-spacing (n): close=c, distant=d, none=f\\n8. gill-color (n): see cap-color + none=f\\n9. stem-height (m): float number in cm\\n10. stem-width (m): float number in mm\\n11. stem-root (n): bulbous=b, swollen=s, club=c, cup=u, equal=e,\\nrhizomorphs=z, rooted=r\\n12. stem-surface (n): see cap-surface + none=f\\n13. stem-color (n): see cap-color + none=f\\n14. veil-type (n): partial=p, universal=u\\n15. veil-color (n): see cap-color + none=f\\n16. has-ring (n): ring=t, none=f\\n17. ring-type (n): cobwebby=c, evanescent=e, flaring=r, grooved=g,\\nlarge=l, pendant=p, sheathing=s, zone=z, scaly=y, movable=m, none=f, unknown=?\\n18. spore-print-color (n): see cap color\\n19. habitat (n): grasses=g, leaves=l, meadows=m, paths=p, heaths=h,\\nurban=u, waste=w, woods=d\\n20. season (n): spring=s, summer=u, autumn=a, winter=w', 'citation': None}}\n",
            "                    name     role         type demographic description units  \\\n",
            "0                  class   Target  Categorical        None        None  None   \n",
            "1           cap-diameter  Feature   Continuous        None        None  None   \n",
            "2              cap-shape  Feature  Categorical        None        None  None   \n",
            "3            cap-surface  Feature  Categorical        None        None  None   \n",
            "4              cap-color  Feature  Categorical        None        None  None   \n",
            "5   does-bruise-or-bleed  Feature  Categorical        None        None  None   \n",
            "6        gill-attachment  Feature  Categorical        None        None  None   \n",
            "7           gill-spacing  Feature  Categorical        None        None  None   \n",
            "8             gill-color  Feature  Categorical        None        None  None   \n",
            "9            stem-height  Feature   Continuous        None        None  None   \n",
            "10            stem-width  Feature   Continuous        None        None  None   \n",
            "11             stem-root  Feature  Categorical        None        None  None   \n",
            "12          stem-surface  Feature  Categorical        None        None  None   \n",
            "13            stem-color  Feature  Categorical        None        None  None   \n",
            "14             veil-type  Feature  Categorical        None        None  None   \n",
            "15            veil-color  Feature  Categorical        None        None  None   \n",
            "16              has-ring  Feature  Categorical        None        None  None   \n",
            "17             ring-type  Feature  Categorical        None        None  None   \n",
            "18     spore-print-color  Feature  Categorical        None        None  None   \n",
            "19               habitat  Feature  Categorical        None        None  None   \n",
            "20                season  Feature  Categorical        None        None  None   \n",
            "\n",
            "   missing_values  \n",
            "0              no  \n",
            "1              no  \n",
            "2              no  \n",
            "3             yes  \n",
            "4              no  \n",
            "5              no  \n",
            "6             yes  \n",
            "7             yes  \n",
            "8              no  \n",
            "9              no  \n",
            "10             no  \n",
            "11            yes  \n",
            "12            yes  \n",
            "13             no  \n",
            "14            yes  \n",
            "15            yes  \n",
            "16             no  \n",
            "17            yes  \n",
            "18            yes  \n",
            "19             no  \n",
            "20             no  \n"
          ]
        }
      ],
      "source": [
        "# Para instalar el repositorio de la UCI\n",
        "!pip install ucimlrepo\n",
        "\n",
        "# Para importar los datos del repositorio\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "secondary_mushroom = fetch_ucirepo(id=848)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = secondary_mushroom.data.features\n",
        "y = secondary_mushroom.data.targets\n",
        "\n",
        "# metadata\n",
        "print(secondary_mushroom.metadata)\n",
        "\n",
        "# variable information\n",
        "print(secondary_mushroom.variables)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c1VROf_hD-f"
      },
      "source": [
        "**2ºForma**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmb8u17ShxrN"
      },
      "outputs": [],
      "source": [
        "#Para acceder a nuestros ficheros de Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataFolder = 'drive/MyDrive/Colab Notebooks/MushroomDataset/Setas/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s97tJ_2l1xd"
      },
      "outputs": [],
      "source": [
        "# Ruta de los archivos CSV en tu carpeta de Google Drive\n",
        "primary_data_path = '/content/drive/MyDrive/Colab Notebooks/Setas/MushroomDataset/primary_data.csv'\n",
        "secondary_data_path = '/content/drive/MyDrive/Colab Notebooks/Setas/MushroomDataset/secondary_data.csv'\n",
        "\n",
        "# Cargar datos primarios\n",
        "primary_data = pd.read_csv(primary_data_path, delimiter=';')\n",
        "\n",
        "# Cargar datos secundarios\n",
        "secondary_data = pd.read_csv(secondary_data_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeIQWvZguoT7"
      },
      "source": [
        "***Vista inicial de los datos***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM6oxVjbutzd"
      },
      "outputs": [],
      "source": [
        "# Cargar el archivo CSV primario\n",
        "df = pd.read_csv(primary_data_path, delimiter=';')\n",
        "\n",
        "# Contar la cantidad de especies por familia\n",
        "species_per_family = df['family'].value_counts()\n",
        "\n",
        "# Ordenar las familias por cantidad de especies (de mayor a menor)\n",
        "species_per_family = species_per_family.sort_values(ascending=True)\n",
        "\n",
        "# Crear el gráfico de barras horizontales\n",
        "plt.figure(figsize=(10, 8))\n",
        "species_per_family.plot(kind='barh', color='purple')\n",
        "plt.xlabel('Cantidad de Especies')\n",
        "plt.ylabel('Familia de Setas')\n",
        "plt.title('Cantidad de Especies de Setas por Familia')\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdq_KVNKX_qO"
      },
      "source": [
        "## 2. Preprocesamiento de los Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSXPnFT0Y1UB"
      },
      "outputs": [],
      "source": [
        "# Imprimir el numero de caracteristicas\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgtMn0cv5Twf"
      },
      "source": [
        "###PRUEBAS ANDRES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJ0hhKZz5M7x"
      },
      "source": [
        "Vamos a ver cuantos valores faltantes tenemos en cada columna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0idbKgDZ5KyS"
      },
      "outputs": [],
      "source": [
        "missing_values = X.isnull().sum()\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4t0b5mP7kTy"
      },
      "source": [
        "Se observa como hay varias columnas con muchos datos faltantes , por lo que podriamos pensar que es mejor borrar estas caracteristicas directamente.\n",
        "\n",
        "por ejemplo: stem-root, veil-type, veil-color y spore-paint-color tienen > 50000 valores faltantes (de 61069)\n",
        "\n",
        "Quizás para el resto de columnas con valores faltantes, podriamos hacerle un input con la media o la moda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNv_8ZJaAWcL"
      },
      "outputs": [],
      "source": [
        "# Separar columnas numéricas y categóricas\n",
        "numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rEEiSKLAuQ3"
      },
      "outputs": [],
      "source": [
        "# Verificar valores faltantes\n",
        "missing_values = X.isnull().sum()\n",
        "total_rows = X.shape[0]\n",
        "\n",
        "# Definir umbral (por ejemplo, 50%)\n",
        "threshold = 0.5\n",
        "\n",
        "# Eliminar columnas con más del 50% de valores faltantes\n",
        "columns_to_drop = missing_values[missing_values > threshold * total_rows].index\n",
        "X_clean = X.drop(columns=columns_to_drop,inplace=False)\n",
        "\n",
        "\n",
        "print(\"Columnas eliminadas debido a muchos valores faltantes:\", columns_to_drop)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReWHh-EpA3Zy"
      },
      "outputs": [],
      "source": [
        "X_clean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-s_PJZNA_Vl"
      },
      "outputs": [],
      "source": [
        "missing_values = X_clean.isnull().sum()\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp1jXkI0BFQ1"
      },
      "outputs": [],
      "source": [
        "# Imputar valores faltantes en columnas numéricas con la media\n",
        "X_clean[numeric_cols] = X_clean[numeric_cols].fillna(X_clean[numeric_cols].mean())\n",
        "\n",
        "# Imputar valores faltantes en columnas categóricas con la moda\n",
        "#X_clean[categorical_cols] = X_clean[categorical_cols].apply(lambda x: x.fillna(x.mode()[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MW4JFFhnBThW"
      },
      "outputs": [],
      "source": [
        "# Convertir variables categóricas a variables dummy (one-hot encoding)\n",
        "X_encoded = pd.get_dummies(X_clean)\n",
        "# Eliminar filas duplicadas\n",
        "X_final = X_encoded.drop_duplicates()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StDIJ3EJBY_Q"
      },
      "outputs": [],
      "source": [
        "X_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waV0V0WABqXY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Normalizar/estandarizar los datos\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X_final), columns=X_final.columns)\n",
        "\n",
        "print(\"Dataset limpio y preparado:\\n\", X_scaled.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ty-L5duCY_a"
      },
      "outputs": [],
      "source": [
        "y = y.reset_index(drop=True)\n",
        "\n",
        "# Eliminar filas duplicadas en X_encoded y sincronizar y\n",
        "X_final = X_encoded.drop_duplicates()\n",
        "y_final = y.loc[X_final.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alqATossB2TK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separar los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_final, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLU0LRiJB6Qi"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Inicializar el modelo\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Entrenar el modelo\n",
        "clf.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjUW5l24B88r"
      },
      "outputs": [],
      "source": [
        "# Predecir los valores del conjunto de prueba\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calcular la precisión del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Precisión del modelo: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKQ2CNVuCm6M"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Validación cruzada con 5 folds\n",
        "cv_scores = cross_val_score(clf, X_scaled, y_final, cv=5)\n",
        "\n",
        "print(f\"Puntuaciones de validación cruzada: {cv_scores}\")\n",
        "print(f\"Precisión media de validación cruzada: {cv_scores.mean():.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrBQ2WZR8kHF"
      },
      "source": [
        "###--"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmxBq11O63EP",
        "outputId": "960a6ab7-a8e4-437a-9a73-bdb7f6b59b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Installing collected packages: scikit-learn\n",
            "Successfully installed scikit-learn-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-ZDck7N_hRB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "45df2bf9-9e48-4c4a-a3b5-17881d31cd86"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name '_fit_context' from 'sklearn.base' (/usr/local/lib/python3.10/dist-packages/sklearn/base.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-29a18d4259de>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from ._data import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mBinarizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mKernelCenterer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mboxcox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from ..base import (\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mClassNamePrefixFeaturesOutMixin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_fit_context' from 'sklearn.base' (/usr/local/lib/python3.10/dist-packages/sklearn/base.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Supongamos que X y y contienen tus datos y etiquetas respectivamente\n",
        "\n",
        "# Inicializar el codificador OneHotEncoder\n",
        "encoder = OneHotEncoder()\n",
        "\n",
        "# Convertir las características categóricas en variables dummy\n",
        "X_encoded = encoder.fit_transform(X)\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Inicializar el clasificador de Random Forest\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Entrenar el clasificador\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Generar cinco ejemplos\n",
        "for i in range(5):\n",
        "    # Seleccionar un índice aleatorio del conjunto de prueba\n",
        "    random_index = np.random.randint(0, X_test.shape[0])\n",
        "    example_X = X_test[random_index]\n",
        "    example_y_true = y_test[random_index]\n",
        "\n",
        "    # Predecir la etiqueta para el ejemplo\n",
        "    example_y_pred = rf_classifier.predict(example_X.reshape(1, -1))[0]\n",
        "\n",
        "    # Imprimir el ejemplo y la predicción\n",
        "    print(\"Ejemplo {}: Características: {}, Etiqueta Verdadera: {}, Predicción: {}\".format(i+1, example_X, example_y_true, example_y_pred))\n",
        "\n",
        "# Calcular la precisión del modelo\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nPrecisión del modelo de Random Forest:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbIxg0mgE-W6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "culTQ05PdXyQ"
      },
      "source": [
        "# Bibliografia\n",
        "- Paper 1: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10428619&tag=1\n",
        "- Notebook 1: https://www.kaggle.com/code/nirajvermafcb/comparing-various-ml-models-roc-curve-comparison"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}